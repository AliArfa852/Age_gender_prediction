{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WdNqjhWOkrcw",
        "outputId": "31f6ac23-b5b2-420f-bd67-2a297d3b95be",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 356
        }
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "MessageError",
          "evalue": "Error: credential propagation was unsuccessful",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mMessageError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-d8a8830f5801>\u001b[0m in \u001b[0;36m<cell line: 15>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;31m# Mount Google Drive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m \u001b[0mdrive\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/drive'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;31m# Define the path to the \"utkcropped\" folder\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/colab/drive.py\u001b[0m in \u001b[0;36mmount\u001b[0;34m(mountpoint, force_remount, timeout_ms, readonly)\u001b[0m\n\u001b[1;32m     98\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mmount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmountpoint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mforce_remount\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout_ms\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m120000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreadonly\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m   \u001b[0;34m\"\"\"Mount your Google Drive at the specified mountpoint path.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 100\u001b[0;31m   return _mount(\n\u001b[0m\u001b[1;32m    101\u001b[0m       \u001b[0mmountpoint\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m       \u001b[0mforce_remount\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mforce_remount\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/colab/drive.py\u001b[0m in \u001b[0;36m_mount\u001b[0;34m(mountpoint, force_remount, timeout_ms, ephemeral, readonly)\u001b[0m\n\u001b[1;32m    131\u001b[0m   )\n\u001b[1;32m    132\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mephemeral\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 133\u001b[0;31m     _message.blocking_request(\n\u001b[0m\u001b[1;32m    134\u001b[0m         \u001b[0;34m'request_auth'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequest\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'authType'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'dfs_ephemeral'\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout_sec\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    135\u001b[0m     )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/colab/_message.py\u001b[0m in \u001b[0;36mblocking_request\u001b[0;34m(request_type, request, timeout_sec, parent)\u001b[0m\n\u001b[1;32m    174\u001b[0m       \u001b[0mrequest_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparent\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexpect_reply\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    175\u001b[0m   )\n\u001b[0;32m--> 176\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mread_reply_from_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout_sec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/colab/_message.py\u001b[0m in \u001b[0;36mread_reply_from_input\u001b[0;34m(message_id, timeout_sec)\u001b[0m\n\u001b[1;32m    101\u001b[0m     ):\n\u001b[1;32m    102\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0;34m'error'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mreply\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 103\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mMessageError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreply\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'error'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    104\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mreply\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'data'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mMessageError\u001b[0m: Error: credential propagation was unsuccessful"
          ]
        }
      ],
      "source": [
        "import re\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from pathlib import Path\n",
        "from google.colab import drive\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense\n",
        "\n",
        "# Mount Google Drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Define the path to the \"utkcropped\" folder\n",
        "path = Path(\"/content/drive/MyDrive/utkcropped/\")\n",
        "\n",
        "# Get filenames of JPEG images\n",
        "filenames = list(map(lambda x: x.name, path.glob('*.jpg')))\n",
        "\n",
        "# Shuffle filenames\n",
        "np.random.seed(10)\n",
        "np.random.shuffle(filenames)\n",
        "\n",
        "# Initialize lists for labels and image paths\n",
        "age_labels, gender_labels, image_path = [], [], []\n",
        "\n",
        "# Define regular expression pattern to extract age and gender\n",
        "pattern = r\"(\\d+)_(\\d)_\\d+_\\d+\\.jpg\\.chip\"\n",
        "\n",
        "# Extract labels from filenames\n",
        "for filename in filenames:\n",
        "    match = re.match(pattern, filename)\n",
        "    if match:\n",
        "        age_labels.append(int(match.group(1)))\n",
        "        gender_labels.append(int(match.group(2)))\n",
        "        image_path.append(str(path / filename))\n",
        "\n",
        "# Create DataFrame\n",
        "df = pd.DataFrame()\n",
        "df['image'], df['age'], df['gender'] = image_path, age_labels, gender_labels\n",
        "\n",
        "# Convert gender labels to integer\n",
        "df['gender'] = df['gender'].astype('int32')\n",
        "\n",
        "# Convert age labels to float\n",
        "df['age'] = df['age'].astype('float32')\n",
        "\n",
        "# Preprocess the images\n",
        "def preprocess_image(image_path):\n",
        "    img = load_img(image_path, target_size=(224, 224))  # Resize images to 224x224 (adjust as needed)\n",
        "    img = img_to_array(img) / 255.0  # Normalize pixel values to [0, 1]\n",
        "    return img\n",
        "\n",
        "# Load and preprocess images\n",
        "X = np.array([preprocess_image(image) for image in df['image']])\n",
        "y = df['age'].values\n",
        "\n",
        "# Check the size of the dataset\n",
        "print(\"Number of samples in the dataset:\", len(X))\n",
        "\n",
        "# Check the first few image paths to verify they are correct\n",
        "print(\"First few image paths:\", image_path[:5])\n",
        "\n",
        "# Check if the images are successfully loaded and preprocessed\n",
        "print(\"Shape of preprocessed images:\", X.shape)\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "\n",
        "# Define early stopping callback\n",
        "early_stopping = EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)\n",
        "\n",
        "# Define the model architecture with added complexity\n",
        "model = Sequential([\n",
        "    Conv2D(64, (3, 3), activation='relu', input_shape=(224, 224, 3)),\n",
        "    MaxPooling2D((2, 2)),\n",
        "    Conv2D(128, (3, 3), activation='relu'),\n",
        "    MaxPooling2D((2, 2)),\n",
        "    Conv2D(256, (3, 3), activation='relu'),\n",
        "    MaxPooling2D((2, 2)),\n",
        "    Conv2D(512, (3, 3), activation='relu'),\n",
        "    MaxPooling2D((2, 2)),\n",
        "    Flatten(),\n",
        "    Dense(256, activation='relu'),\n",
        "    Dense(1)  # Output layer for age prediction\n",
        "])\n",
        "\n",
        "# Compile the model with a lower learning rate and using mean absolute error as the loss function\n",
        "model.compile(optimizer='adam', loss='mean_absolute_error')\n",
        "\n",
        "# Train the model with data augmentation and early stopping\n",
        "history = model.fit(\n",
        "    X_train, y_train,\n",
        "    epochs=50,\n",
        "    batch_size=32,\n",
        "    validation_data=(X_test, y_test),\n",
        "    callbacks=[early_stopping]\n",
        ")\n",
        "\n",
        "# Evaluate the model\n",
        "loss = model.evaluate(X_test, y_test)\n",
        "print(\"Test Loss:\", loss)\n",
        "\n",
        "# Save the model if needed\n",
        "model.save(\"/content/drive/MyDrive/age_prediction_model.h5\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ***Testing Cell***"
      ],
      "metadata": {
        "id": "bnbbE1gp36wl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import load_model\n",
        "from tensorflow.keras.preprocessing.image import img_to_array\n",
        "import numpy as np\n",
        "\n",
        "def predict_age_and_gender(image_var):\n",
        "    # Load the trained model\n",
        "    model = load_model(\"/content/drive/MyDrive/age_and_gender_prediction_model.h5\")\n",
        "\n",
        "    # Preprocess the image\n",
        "    img_array = img_to_array(image_var) / 255.0\n",
        "    img_array = np.expand_dims(img_array, axis=0)  # Add batch dimension\n",
        "\n",
        "    # Make prediction\n",
        "    prediction = model.predict(img_array)[0]\n",
        "    predicted_age = prediction[0]\n",
        "    predicted_gender = \"Male\" if prediction[1] < 0.5 else \"Female\"\n",
        "\n",
        "    return predicted_age, predicted_gender\n",
        "\n",
        "image_var = 'D.jpg'\n",
        "predicted_age, predicted_gender = predict_age_and_gender(image_var)\n",
        "print(\"Predicted age:\", predicted_age)\n",
        "print(\"Predicted gender:\", predicted_gender)\n"
      ],
      "metadata": {
        "id": "A8_X3Zo6qF-d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 356
        },
        "outputId": "295c46dd-36dd-4787-bf1a-1fe8b0f4b206"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "OSError",
          "evalue": "No file or directory found at /content/drive/MyDrive/age_and_gender_prediction_model.h5",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-3-3d52d66332e7>\u001b[0m in \u001b[0;36m<cell line: 21>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0mimage_var\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'D.jpg'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m \u001b[0mpredicted_age\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpredicted_gender\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpredict_age_and_gender\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage_var\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Predicted age:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpredicted_age\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Predicted gender:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpredicted_gender\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-3-3d52d66332e7>\u001b[0m in \u001b[0;36mpredict_age_and_gender\u001b[0;34m(image_var)\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mpredict_age_and_gender\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage_var\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0;31m# Load the trained model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"/content/drive/MyDrive/age_and_gender_prediction_model.h5\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0;31m# Preprocess the image\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/saving/saving_api.py\u001b[0m in \u001b[0;36mload_model\u001b[0;34m(filepath, custom_objects, compile, safe_mode, **kwargs)\u001b[0m\n\u001b[1;32m    260\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    261\u001b[0m     \u001b[0;31m# Legacy case.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 262\u001b[0;31m     return legacy_sm_saving_lib.load_model(\n\u001b[0m\u001b[1;32m    263\u001b[0m         \u001b[0mfilepath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcustom_objects\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcustom_objects\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcompile\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    264\u001b[0m     )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     68\u001b[0m             \u001b[0;31m# To get the full stack trace, call:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m             \u001b[0;31m# `tf.debugging.disable_traceback_filtering()`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m             \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/saving/legacy/save.py\u001b[0m in \u001b[0;36mload_model\u001b[0;34m(filepath, custom_objects, compile, options)\u001b[0m\n\u001b[1;32m    232\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_str\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    233\u001b[0m                         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgfile\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexists\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_str\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 234\u001b[0;31m                             raise IOError(\n\u001b[0m\u001b[1;32m    235\u001b[0m                                 \u001b[0;34mf\"No file or directory found at {filepath_str}\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    236\u001b[0m                             )\n",
            "\u001b[0;31mOSError\u001b[0m: No file or directory found at /content/drive/MyDrive/age_and_gender_prediction_model.h5"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# from tensorflow.keras.models import load_model\n",
        "# from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
        "# import numpy as np\n",
        "\n",
        "# def predict_age_and_gender(image_var):\n",
        "#     # Load the trained model\n",
        "#     model = load_model(\"/content/drive/MyDrive/age_prediction_model.h5\")\n",
        "\n",
        "#     # Preprocess the image\n",
        "#     img_array = img_to_array(image_var) / 255.0\n",
        "#     img_array = np.expand_dims(img_array, axis=0)  # Add batch dimension\n",
        "\n",
        "#     # Make prediction\n",
        "#     predicted_age = model.predict(img_array)[0][0]\n",
        "\n",
        "#     return predicted_age\n",
        "\n",
        "# # Assuming you have an image variable named 'image_var'\n",
        "# image_var ='download.jpg'\n",
        "# predicted_age, predicted_gender = predict_age_and_gender(image_var)\n",
        "# print(\"Predicted age:\", predicted_age)\n"
      ],
      "metadata": {
        "id": "Z4VbDm0GWwz7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from pathlib import Path\n",
        "from google.colab import drive\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.models import Sequential, load_model\n",
        "from tensorflow.keras.applications import VGG16\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator, load_img, img_to_array\n",
        "from tensorflow.keras.layers import Flatten, Dense\n",
        "\n",
        "# Mount Google Drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Define the path to the \"utkcropped\" folder\n",
        "path = Path(\"/content/drive/My Drive/utkcropped\")\n",
        "\n",
        "# Get filenames of JPEG images\n",
        "filenames = list(map(lambda x: x.name, path.glob('*.jpg')))\n",
        "\n",
        "# Shuffle filenames\n",
        "np.random.seed(10)\n",
        "np.random.shuffle(filenames)\n",
        "\n",
        "# Initialize lists for labels and image paths\n",
        "age_labels, gender_labels, image_path = [], [], []\n",
        "\n",
        "# Define regular expression pattern to extract age and gender\n",
        "pattern = r\"(\\d+)_(\\d)_\\d+_\\d+\\.jpg\\.chip\"\n",
        "\n",
        "# Extract labels from filenames\n",
        "for filename in filenames:\n",
        "    match = re.match(pattern, filename)\n",
        "    if match:\n",
        "        age_labels.append(int(match.group(1)))\n",
        "        gender_labels.append(int(match.group(2)))\n",
        "        image_path.append(str(path / filename))\n",
        "\n",
        "# Create DataFrame\n",
        "df = pd.DataFrame()\n",
        "df['image'], df['age'], df['gender'] = image_path, age_labels, gender_labels\n",
        "\n",
        "# Convert gender labels to integer\n",
        "df['gender'] = df['gender'].astype('int32')\n",
        "\n",
        "# Convert age labels to float\n",
        "df['age'] = df['age'].astype('float32')\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "train_df, test_df = train_test_split(df, test_size=0.2, random_state=42)\n",
        "\n",
        "# Create data generators\n",
        "train_datagen = ImageDataGenerator(\n",
        "    rescale=1.0 / 255.0,\n",
        "    rotation_range=10,\n",
        "    width_shift_range=0.1,\n",
        "    height_shift_range=0.1,\n",
        "    shear_range=0.1,\n",
        "    zoom_range=0.1,\n",
        "    horizontal_flip=True\n",
        ")\n",
        "\n",
        "test_datagen = ImageDataGenerator(rescale=1.0 / 255.0)\n",
        "\n",
        "# Define batch size\n",
        "batch_size = 32\n",
        "\n",
        "# Flow training images in batches\n",
        "train_generator = train_datagen.flow_from_dataframe(\n",
        "    dataframe=train_df,\n",
        "    x_col=\"image\",\n",
        "    y_col=[\"age\", \"gender\"],  # Predict both age and gender\n",
        "    target_size=(224, 224),\n",
        "    batch_size=batch_size,\n",
        "    class_mode=\"raw\"\n",
        ")\n",
        "\n",
        "# Flow validation images in batches\n",
        "validation_generator = test_datagen.flow_from_dataframe(\n",
        "    dataframe=test_df,\n",
        "    x_col=\"image\",\n",
        "    y_col=[\"age\", \"gender\"],  # Predict both age and gender\n",
        "    target_size=(224, 224),\n",
        "    batch_size=batch_size,\n",
        "    class_mode=\"raw\"\n",
        ")\n",
        "\n",
        "# Define early stopping callback\n",
        "early_stopping = EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)\n",
        "\n",
        "# Define the base model (pre-trained VGG16 model)\n",
        "base_model = VGG16(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
        "\n",
        "# Freeze the layers in the base model\n",
        "base_model.trainable = False\n",
        "\n",
        "# Define the model architecture with transfer learning\n",
        "model = Sequential([\n",
        "    base_model,\n",
        "    Flatten(),\n",
        "    Dense(256, activation='relu'),\n",
        "    Dense(2)  # Output layer for age and gender prediction\n",
        "])\n",
        "\n",
        "# Compile the model with a lower learning rate and using mean absolute error as the loss function\n",
        "model.compile(optimizer='adam', loss='mean_absolute_error')\n",
        "\n",
        "# Train the model with data generators and early stopping\n",
        "history = model.fit(\n",
        "    train_generator,\n",
        "    steps_per_epoch=len(train_generator),\n",
        "    epochs=50,\n",
        "    validation_data=validation_generator,\n",
        "    validation_steps=len(validation_generator),\n",
        "    callbacks=[early_stopping]\n",
        ")\n",
        "\n",
        "# Save the model if needed\n",
        "model.save(\"/content/drive/My Drive/age_and_gender_prediction_model_v2.h5\")\n",
        "\n"
      ],
      "metadata": {
        "id": "CnwzfTpa4_vq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Testing cell 2**"
      ],
      "metadata": {
        "id": "s8f-jkgy9ud7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import load_model\n",
        "from tensorflow.keras.preprocessing.image import img_to_array\n",
        "import numpy as np\n",
        "\n",
        "def predict_age_and_gender(image_var):\n",
        "    # Load the trained model\n",
        "    model = load_model(\"/content/drive/MyDrive/age_and_gender_prediction_model_v2.h5\")\n",
        "\n",
        "    # Preprocess the image\n",
        "    img_array = img_to_array(image_var) / 255.0\n",
        "    img_array = np.expand_dims(img_array, axis=0)  # Add batch dimension\n",
        "\n",
        "    # Make prediction\n",
        "    prediction = model.predict(img_array)[0]\n",
        "    predicted_age = prediction[0]\n",
        "    predicted_gender = \"Male\" if prediction[1] < 0.5 else \"Female\"\n",
        "\n",
        "    return predicted_age, predicted_gender\n",
        "\n",
        "# Example usage:\n",
        "image_var = \"download.jpg\"\n",
        "predicted_age, predicted_gender = predict_age_and_gender(image_var)\n",
        "print(\"Predicted age:\", predicted_age)\n",
        "print(\"Predicted gender:\", predicted_gender)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "GXdbaf295U7r"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}